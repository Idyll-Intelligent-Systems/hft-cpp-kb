# Division Nodes

**Problem Statement**

You are given a tree with `N` nodes labelled from `1` to `N`. The tree contains `N-1` edges listed in array `edges`. Each node `i` has a value `A[i]`.

Your task is to remove **one** edge so that the absolute difference between the sum of node values on the two resulting components is minimized. Output the index (1-based) of the edge that should be removed. If multiple edges give the same minimal difference, choose the smallest index.

## Input Format

1. `T` &ndash; number of test cases.
2. For each test case:
   - A line containing integer `N`.
   - The next `N-1` lines each contain two integers `u v` describing an edge.
   - A line of `N` space-separated integers giving the node values `A[i]`.

## Output Format

For each test case output a single integer: the index of the edge to remove.

## Constraints

- `2 \le N \le 10^5`
- Node values fit in 32-bit signed integers.

## Example

```
Input
1
3
1 2
2 3
10 5 7

Output
2
```

Removing the second edge `[2,3]` splits the tree into values `10+5=15` and `7`. The difference `|15 - 7| = 8` is minimal for this example.
